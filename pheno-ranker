#!/usr/bin/env perl
#
#   A script that ranks individuals against a cohort (BFF)
#
#   Last Modified: Apr/17/2023
#
#   Version 1.0.0
#
#   Copyright (C) 2023 Manuel Rueda - CNAG (manuel.rueda@cnag.crg.eu)
#
#   This program is free software; you can redistribute it and/or modify
#   it under the terms of the GNU General Public License as published by
#   the Free Software Foundation; either version 3 of the License, or
#   (at your option) any later version.
#
#   This program is distributed in the hope that it will be useful,
#   but WITHOUT ANY WARRANTY; without even the implied warranty of
#   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
#   GNU General Public License for more details.
#
#   You should have received a copy of the GNU General Public License
#   along with this program; if not, see <https://www.gnu.org/licenses/>.
#
#   If this program helps you in your research, please cite.

use strict;
use warnings;
use feature qw(say);
use autodie;
use Getopt::Long qw(:config no_ignore_case);
use Pod::Usage;
use Data::Dumper;
use Sys::Hostname;
use POSIX           qw(strftime);
use Term::ANSIColor qw(:constants);
use Path::Tiny;
use JSON::XS;
use YAML::XS qw(LoadFile);
use Sort::Naturally;
use Hash::Fold fold => { array_delimiter => ':' };
use Math::CDF qw(pnorm pbinom);
use Statistics::Descriptive;

my $debug   = 0;
my $verbose = 0;

##### Main #####
pheno_ranker();
################
exit;

sub pheno_ranker {

    # Defining a few variables
    my $VERSION     = '1.0.0';
    my $output_file = 'matrix.txt';
    my $align_file  = 'alignment.txt';
    my $sort_by     = 'hamming';
    my $max_out     = 50;
    my $hpo_file    = 'db/hp.json';

    # Reading arguments
    GetOptions(
        'reference|r=s' => \my $reference_file,                       # string
        'target|t=s'    => \my $target_file,                          # string
        'weights|w=s'   => \my $weights_file,                         # string
        'o=s'           => \$output_file,                             # string
        'max-out:i'     => \$max_out,                                 # integer
        'hpo'           => \my $hpo,                                  # flag
        'export|e'      => \my $export,                               # flag
        'align|a:s'     => \my $align,                                # opt-string (defined)
        'sort-by=s'     => \$sort_by,                                 # string
        'help|?'        => \my $help,                                 # flag
        'log:s'         => \my $log,                                  # opt-string (defined)
        'man'           => \my $man,                                  # flag
        'debug=i'       => \$debug,                                   # integer
        'verbose|'      => \$verbose,                                 # flag
        'no-color|nc'   => \my $no_color,                             # flag
        'version|V'     => sub { say "$0 Version $VERSION"; exit; }
    ) or pod2usage(2);
    pod2usage(1)                              if $help;
    pod2usage( -verbose => 2, -exitval => 0 ) if $man;
    pod2usage(
        -message => "Please specify a valid reference-cohort for -r\n",
        -exitval => 1
    ) unless $reference_file;
    pod2usage(
        -message =>
          "Please specify a valid --sort-by method <hamming|jaccard>\n",
        -exitval => 1
    ) unless ( $sort_by eq 'hamming' || $sort_by eq 'jaccard' );
    pod2usage(
        -message => "We could not find <$hpo_file>\n",
        -exitval => 1
    ) if ( $hpo && !-f $hpo_file );

    # Turning color off if argument <--no-color>
    $ENV{'ANSI_COLORS_DISABLED'} = 1 if $no_color;

    # Start printing to STDOUT
    say BOLD CYAN program_header($VERSION), RESET if $verbose;

    # Load JSON files as Perl data structure
    my $ref_data = read_json($reference_file);

    # We assing weights if <--w>
    # NB: The user can exclude variables by using variable: 0
    my $weight =
      ( $weights_file && -f $weights_file ) ? read_yaml($weights_file) : undef;

    # Now we load $hpo_nodes, $hpo_edges if --hpo
    my $nodes = my $term_parents = undef;
    ( $nodes, $term_parents ) = parse_hpo_json( read_json($hpo_file) ) if $hpo;

    # First we create:
    # - $glob_hash => hash with all the cohort keys possible
    # - $ref_hash  => BIG hash with all individiduals' keys "flattened"
    my ( $glob_hash, $ref_hash ) =
      create_glob_and_ref_hashes( $ref_data, $weight, $term_parents );

    # Second we peform one-hot encoding for each individual
    my $ref_binary_hash =
      create_weigthted_binary_digit_string( $glob_hash, $ref_hash );

    # Hases to be serialized to JSON if <--export>
    my $hash2serialize = {
        glob_hash       => $glob_hash,
        ref_hash        => $ref_hash,
        ref_binary_hash => $ref_binary_hash
    };

    # Perform intra-cohort comparison if <--r>
    intra_cohort_comparison( $ref_binary_hash, $output_file )
      unless $target_file;

    # Perform patient-to-cohort comparison and rank if <--t>
    if ($target_file) {
        my $tar_data = read_json($target_file);
        my $tar_hash = { $tar_data->{id} => remap_hash( $tar_data, $weight ) };
        my $tar_binary_hash =
          create_weigthted_binary_digit_string( $glob_hash, $tar_hash );
        my ( $results_rank, $results_align, $alignments_array ) =
          compare_and_rank(
            {
                glob_hash       => $glob_hash,
                ref_binary_hash => $ref_binary_hash,
                tar_binary_hash => $tar_binary_hash,
                weight          => $weight,
                sort_by         => $sort_by,
                align           => $align,
                max_out         => $max_out
            }
          );

        # Print Ranked results to STDOUT
        say join "\n", @$results_rank;

        # Write TXT for alignment
        write_alignment( $align ? $align : $align_file, $alignments_array )
          if defined $align;

        # Load keys into hash if <--e>
        if ($export) {
            $hash2serialize->{tar_hash}        = $tar_hash;
            $hash2serialize->{tar_binary_hash} = $tar_binary_hash;
            $hash2serialize->{alignment_hash}  = $results_align
              if defined $align;
        }
    }

    # Dump to JSON if <--export>
    serialize_hashes($hash2serialize) if $export;

    # Create log if <--log>
    write_log( $log ? $log : 'pheno-ranker-log.json',
        { reference => $reference_file, target => $target_file }, $VERSION )
      if defined $log;
}

sub serialize_hashes {

    my $arg = shift;
    write_json( { data => $arg->{$_}, filepath => qq/$_.json/ } )
      for keys %{$arg};
    return 1;
}

sub intra_cohort_comparison {

    my ( $ref_binary_hash, $output ) = @_;
    my @sorted_keys_ref_binary_hash = nsort( keys %{$ref_binary_hash} );

    say "Performing INTRA-COHORT compariSon" if ( $debug || $verbose );

    # Print to  $output
    open( my $fh, ">", $output );
    say $fh "\t", join "\t", @sorted_keys_ref_binary_hash;

    # NB: It's a symmetric matrix so we could just compute
    #     triangle. However,  R needs the whole matrix
    #     Hammind distance is very fast, but
    #     I will re-implement if time becomes a bottleneck

    # I elements
    for my $i (@sorted_keys_ref_binary_hash) {
        say "Calculating <$i> against the cohort..." if $verbose;
        my $str1 = $ref_binary_hash->{$i};
        print $fh "$i\t";

        # J elements
        for my $j (@sorted_keys_ref_binary_hash) {
            my $str2 = $ref_binary_hash->{$j};
            print $fh hd_fast( $str1, $str2 ), "\t";
        }
        print $fh "\n";
    }
    close $fh;
    say "Matrix saved to <$output>" if ( $debug || $verbose );
    return 1;
}

sub compare_and_rank {

    my $arg             = shift;
    my $glob_hash       = $arg->{glob_hash};
    my $ref_binary_hash = $arg->{ref_binary_hash};
    my $tar_binary_hash = $arg->{tar_binary_hash};
    my $weight          = $arg->{weight};
    my $sort_by         = $arg->{sort_by};
    my $align           = $arg->{align};
    my $max_out         = $arg->{max_out};

    say "Performing COHORT(REF)-PATIENT(TAR) comparison"
      if ( $debug || $verbose );

    # Hash for compiling distances
    my $score;

    # Hash for stats
    my $stat;

    my ($tar) = keys %{$tar_binary_hash};
    my $str2 = $tar_binary_hash->{$tar};

    for my $key ( keys %{$ref_binary_hash} ) {    # No need to sort
        my $str1 = $ref_binary_hash->{$key};
        say "Comparing <id:$key> --- <id:$tar>" if $verbose;
        say "REF:$str1\nTAR:$str2\n"            if $debug > 1;
        $score->{$key}{hamming} = hd_fast( $str1, $str2 );
        $score->{$key}{jaccard} = jaccard_similarity( $str1, $str2 );

        # Add values
        push @{ $stat->{hamming_data} }, $score->{$key}{hamming};
        push @{ $stat->{jaccard_data} }, $score->{$key}{jaccard};
    }
    $stat->{hamming_stats} = add_stats( $stat->{hamming_data} );
    $stat->{jaccard_stats} = add_stats( $stat->{jaccard_data} );

    # Initialize a few variables
    my @headers = (
        'RANK',                   'REFERENCE(ID)',
        'TARGET(ID)',             'LENGTH',
        'WEIGHTED',               'HAMMING-DISTANCE',
        'DISTANCE-Z-SCORE',       'DISTANCE-P-VALUE',
        'DISTANCE-Z-SCORE(RAND)', 'JACCARD-INDEX',
        'JACCARD-Z-SCORE',        'JACCARD-P-VALUE'
    );
    my $header  = join "\t", @headers;
    my @results = $header;
    my @alignments;
    my %info;
    my $length_align = length($str2);
    my $weight_bool  = $weight ? 'True' : 'False';

    # Sort %score by value and load results
    my $count = 1;
    $max_out++;    # to be able to start w/ ONE

    # Start loop
    for my $key (
        sort {
            $sort_by eq 'jaccard'                                    #
              ? $score->{$b}{$sort_by} <=> $score->{$a}{$sort_by}    # 1 to 0 (similarity)
              : $score->{$a}{$sort_by} <=> $score->{$b}{$sort_by}    # 0 to N (distance)
        } keys %$score
      )
    {

        say "$count: Creating alignment <id:$key>" if $verbose;

        # Create ASCII alignemnt
        my ( $n_00, $alignment ) =
          create_alignment( $ref_binary_hash->{$key}, $str2, $glob_hash );

        # Compute estimated av and dev for binary_string of L = length_align - n_00
        # Corrected length_align L = length_align - n_00
        my $length_align_corrected = $length_align - $n_00;
        ( $stat->{hamming_stats}{mean_rnd}, $stat->{hamming_stats}{sd_rnd} ) =
          estimate_hamming_stats($length_align_corrected);

        # Compute a few stats
        my $hamming_z_score = z_score(
            $score->{$key}{hamming},
            $stat->{hamming_stats}{mean},
            $stat->{hamming_stats}{sd}
        );
        my $hamming_z_score_from_random = z_score(
            $score->{$key}{hamming},
            $stat->{hamming_stats}{mean_rnd},
            $stat->{hamming_stats}{sd_rnd}
        );

        #my $hamming_p_value =
        #  p_value( $score->{$key}{hamming}, $length_align_corrected );
        my $hamming_p_value_from_z_score =
          p_value_from_z_score($hamming_z_score);
        my $jaccard_z_score = z_score(
            $score->{$key}{jaccard},
            $stat->{jaccard_stats}{mean},
            $stat->{jaccard_stats}{sd}
        );
        my $jaccard_p_value_from_z_score =
          p_value_from_z_score( 1 - $jaccard_z_score );

        # Create a hash with formats
        my $format = {
            'RANK'          => { value => $count,       format => undef },
            'REFERENCE(ID)' => { value => $key,         format => undef },
            'TARGET(ID)'    => { value => $tar,         format => undef },
            'WEIGHTED'      => { value => $weight_bool, format => undef },
            'LENGTH' => { value => $length_align_corrected, format => '%6d' },
            'HAMMING-DISTANCE' =>
              { value => $score->{$key}{hamming}, format => '%4d' },
            'DISTANCE-Z-SCORE' =>
              { value => $hamming_z_score, format => '%7.3f' },
            'DISTANCE-P-VALUE' =>
              { value => $hamming_p_value_from_z_score, format => '%12.7f' },
            'DISTANCE-Z-SCORE(RAND)' =>
              { value => $hamming_z_score_from_random, format => '%8.4f' },
            'JACCARD-INDEX' =>
              { value => $score->{$key}{jaccard}, format => '%7.3f' },
            'JACCARD-Z-SCORE' =>
              { value => $jaccard_z_score, format => '%7.3f' },
            'JACCARD-P-VALUE' =>
              { value => $jaccard_p_value_from_z_score, format => '%12.7f' },
        };

        # Serialize results
        my $tmp_str = join "\t", map {
            defined $format->{$_}{format}
              ? sprintf( $format->{$_}{format}, $format->{$_}{value} )
              : $format->{$_}{value}
        } @headers;
        push @results, $tmp_str;

        # To save memory only load if --align
        if ( defined $align ) {

            # Add all of the above to @alignments
            my $sep = ('-') x 80;
            push @alignments, qq/#$header\n$tmp_str\n$sep\n$$alignment/;

            # Add values to info
            $info{$key} = {
                  weighted => $weight_bool eq 'True'
                ? JSON::XS::true
                : JSON::XS::false,
                reference_id            => $key,
                target_id               => $tar,
                reference_binary_string => $ref_binary_hash->{$key},
                target_binary_string    => $str2,
                alignment_length        => $length_align_corrected,
                hamming_distance        => $score->{$key}{hamming},
                hamming_z_score         => $hamming_z_score,
                hamming_p_value         => $hamming_p_value_from_z_score,
                jaccard_similarity      => $score->{$key}{jaccard},
                jaccard_z_score         => $jaccard_z_score,
                jaccard_p_value         => $jaccard_p_value_from_z_score,
                jaccard_distance        => 1 - $score->{$key}{jaccard},
                alignment               => $$alignment,
            };
        }

        $count++;
        last if $count == $max_out;
    }
    return \@results, \%info, \@alignments;
}

sub create_alignment {

    my ( $binary_string1, $binary_string2, $glob_hash ) = @_;

    my $length1 = length($binary_string1);
    my $length2 = length($binary_string2);

    die "The binary strings must have the same length"
      if ( $length1 != $length2 );

    # Expand array to have weights as N-elements
    my $recreated_array = recreate_array($glob_hash);

    my $out          = "REF -- TAR\n";
    my $cum_distance = 0;
    my $n_00         = 0;
    for ( my $i = 0 ; $i < $length1 ; $i++ ) {

        my $char1 = substr( $binary_string1, $i, 1 );
        my $char2 = substr( $binary_string2, $i, 1 );
        $n_00++ if ( $char1 == 0 && $char2 == 0 );
        my $key = $recreated_array->[$i];
        my $val = sprintf( "%3d", $glob_hash->{$key} );
        $i = $i + $glob_hash->{$key} - 1;
        $cum_distance += $glob_hash->{$key} if $char1 ne $char2;
        my $cum_distance_pretty = sprintf( "%3d", $cum_distance );
        my $distance            = $char1 eq $char2 ? 0 : $glob_hash->{$key};
        $distance = sprintf( "%3d", $distance );

        my %format = (
            '11' =>
qq/$char1 ----- $char2 | (w:$val|d:$distance|cd:$cum_distance_pretty|) $key/,
            '10' =>
qq/$char1 xxx-- $char2 | (w:$val|d:$distance|cd:$cum_distance_pretty|) $key/,
            '01' =>
qq/$char1 --xxx $char2 | (w:$val|d:$distance|cd:$cum_distance_pretty|) $key/,
            '00' =>
qq/$char1       $char2 | (w:$val|d:$distance|cd:$cum_distance_pretty|) $key/
        );
        $out .= $format{ $char1 . $char2 } . "\n";

    }
    return $n_00, \$out;
}

sub recreate_array {

    my $glob_hash = shift;

    # *** IMPORTANT ***
    # nsort does not yield same results as canonical from JSON::XS
    my @sorted_keys_glob_hash = sort keys %{$glob_hash};
    my @recreated_array;

    foreach my $key (@sorted_keys_glob_hash) {
        for ( my $i = 0 ; $i < $glob_hash->{$key} ; $i++ ) {
            push @recreated_array, $key;
        }
    }
    return \@recreated_array;

}

sub create_glob_and_ref_hashes {

    my ( $array, $weight, $term_parents ) = @_;
    my $glob_hash = {};
    my $ref_hash_flattened;

    for my $i ( @{$array} ) {
        my $id = $i->{id};
        say "Flattening and remapping <id:$id> ..." if $verbose;
        my $ref_hash = remap_hash( $i, $weight, $term_parents );
        $ref_hash_flattened->{$id} = $ref_hash;

        # The idea is to create a $glob_hash with unique key-values
        $glob_hash = { %$glob_hash, %$ref_hash };
    }
    return ( $glob_hash, $ref_hash_flattened );
}

sub discard_excluded_phenotypicFeatures {

    my $hash = shift;
    if ( exists $hash->{phenotypicFeatures} ) {
        map { $_ = $_->{excluded} ? undef : $_ }
          @{ $hash->{phenotypicFeatures} };
    }
    return $hash;
}

sub remap_hash {

    my ( $hash, $weight, $term_parents ) = @_;
    my $out_hash;

    # Do some cleaning first
    $hash = fold( discard_excluded_phenotypicFeatures($hash) );

    # Create the hash once
    my %id_correspondence = (
        measures                  => 'assayCode.id',
        treatments                => 'treatmentCode.id',
        exposures                 => 'exposureCode.id',
        diseases                  => 'diseaseCode.id',
        phenotypicFeatures        => 'featureType.id',
        interventionsOrProcedures => 'procedureCode.id'
    );

    for my $key ( keys %{$hash} ) {

        # To see which ones were discarded
        #say $key if !defined $hash->{$key};

        # Discard undefined
        next unless defined $hash->{$key};

        # Discarding lines with 'low quality' keys (Time of regex profiled with :NYTProf: ms time)
        # Some can be "rescued" by adding the ontology as ($1)
        next
          if $key =~
m/info|notes|label|value|\.high|\.low|metaData|familyHistory|excluded|_visit|dateOfProcedure/;

        # Load values
        my $val = $hash->{$key};

        # Discarding lines with val (Time profiled with :NYTProf: ms time)
        next
          if ( $val eq 'NA'
            || $val eq 'Fake'
            || $val eq 'None:No matching concept'
            || $val =~ m/1900-01-01|NA0000|P999Y|P9999Y|ARRAY|phenopacket_id/ );

        # Add IDs to key
        $key = add_id2key( $key, $hash, \%id_correspondence );

        # Finally add value to key
        my $tmp_key = $key . '.' . $val;

        # Add HPO ascendants
        if ( defined $term_parents && $val =~ /^HP:/ ) {
            my $ascendants = add_hpo_ascendants( $tmp_key, $term_parents );
            $out_hash->{$_} = 1 for @$ascendants;    # weight 1 for now
        }

        # Assign weights
        # NB: mrueda (04-12-23) - it's ok if $weight == undef => NO AUTOVIVIFICATION!
        # NB: We don't warn if it does not exists, just assign 1
        $out_hash->{$tmp_key} =
          exists $weight->{$tmp_key} ? $weight->{$tmp_key} : 1;
    }
    return $out_hash;
}

sub add_hpo_ascendants {

    my ( $key, $term_parents ) = @_;
    say $key;
    $key =~ m/HP:(\w+)$/;
    my $hpo_key = 'http://purl.obolibrary.org/obo/HP_' . $1;

    say "$hpo_key";
    my @ascendants;
    for my $parent_id ( @{ $term_parents->{$hpo_key} } ) {
        $parent_id =~ m/\/(\w+)$/;
        $parent_id = $1;
        $parent_id =~ tr/_/:/;
        my $asc_key = $key . '.asc.' . $parent_id;
        push @ascendants, $asc_key;
    }
    return \@ascendants;
}

sub add_id2key {

    my ( $key, $hash, $id_correspondence ) = @_;
    if ( $key =~
/measures|treatments|exposures|diseases|phenotypicFeatures|interventionsOrProcedures/
      )
    {
        $key =~ m/^(\w+):(\d+)\.(\S+)/;
        my $tmp_key = $1 . ':' . $2 . '.' . $id_correspondence->{$1};
        my $val     = $hash->{$tmp_key};
        $key = $1 . '.' . $val . '.' . $3;
    }
    return $key;
}

sub create_weigthted_binary_digit_string {

    my ( $glob_hash, $cmp_hash ) = @_;
    my $out_hash;

    # *** IMPORTANT ***
    # Being a nested for, keys %{$glob_hash} does not need sorting
    # BUT, we sort to follow the same order as serialized (sorted)
    my @sorted_keys_glob_hash = sort keys %{$glob_hash};

    # IDs of each indidividual
    for my $key1 ( keys %{$cmp_hash} ) {    # no need to sort

        # One-hot encoding = Representing categorical data as numerical
        my $binary_str = '';
        for my $key2 (@sorted_keys_glob_hash) {

            my $ones  = (1) x $glob_hash->{$key2};
            my $zeros = (0) x $glob_hash->{$key2};
            $binary_str .= exists $cmp_hash->{$key1}{$key2} ? $ones : $zeros;
        }
        $out_hash->{$key1} = $binary_str;
    }
    return $out_hash;
}

sub parse_hpo_json {

    my $data = shift;

    # The <hp.json> file is a structured representation of the Human Phenotype Ontology (HPO) in JSON format.
    # The HPO is structured into a directed acyclic graph (DAG)
    # Here's a brief overview of the structure of the hpo.json file:
    # - graphs: This key contains an array of ontology graphs. In the case of HPO, there is only one graph. The graph has two main keys:
    # - nodes: An array of objects, each representing an HPO term. Each term object has the following keys:
    # - id: The identifier of the term (e.g., "HP:0000118").
    # - lbl: The label (name) of the term (e.g., "Phenotypic abnormality").
    # - meta: Metadata associated with the term, including definition, synonyms, and other information.
    # - type: The type of the term, usually "CLASS".
    # - edges: An array of objects, each representing a relationship between two HPO terms. Each edge object has the following keys:
    # - sub: The subject (child) term ID (e.g., "HP:0000924").
    # - obj: The object (parent) term ID (e.g., "HP:0000118").
    # - pred: The predicate that describes the relationship between the subject and object terms, typically "is_a" in HPO.
    # - meta: This key contains metadata about the HPO ontology as a whole, such as version information, description, and other details.

    my $graph = $data->{graphs}->[0];
    my %nodes = map { $_->{id} => $_ } @{ $graph->{nodes} };
    my %edges = ();

    for my $edge ( @{ $graph->{edges} } ) {
        my $child_id  = $edge->{sub};
        my $parent_id = $edge->{obj};
        push @{ $edges{$child_id} }, $parent_id;
    }
    return \%nodes, \%edges;
}

sub hd_fast {

    # Hamming Distance
    return ( $_[0] ^ $_[1] ) =~ tr/\001-\255//;
}

sub jaccard_similarity {

    my ( $str1, $str2 ) = @_;

    # NB: It does not take into account 0 --- 0
    my ( $intersection, $union ) = ( 0, 0 );
    for my $i ( 0 .. length($str1) - 1 ) {
        my $char1 = substr( $str1, $i, 1 );
        my $char2 = substr( $str2, $i, 1 );

        if ( $char1 eq '1' || $char2 eq '1' ) {
            $union++;
            $intersection++ if $char1 eq '1' && $char2 eq '1';
        }
    }
    return $union == 0 ? 0 : $intersection / $union;
}

sub estimate_hamming_stats {

    my $length               = shift;
    my $probability_mismatch = 0.5;
    my $estimated_average    = $length * $probability_mismatch;
    my $estimated_std_dev =
      sqrt( $length * $probability_mismatch * ( 1 - $probability_mismatch ) );
    return $estimated_average, $estimated_std_dev;
}

sub z_score {

    my ( $observed_value, $expected_value, $std_dev ) = @_;
    return ( $observed_value - $expected_value ) / $std_dev;
}

sub p_value_from_z_score {

    return pnorm(shift)    # One-tailed test
}

#sub _p_value {
#
#    my ( $hamming_distance, $string_length ) = @_;
#    my $probability_mismatch = 0.5;
#    return 2 * (1 - pbinom($hamming_distance - 1, $string_length, $probability_mismatch))
#}

sub add_stats {

    my $array = shift;
    my $hash_out;
    my $stat = Statistics::Descriptive::Full->new();
    $stat->add_data($array);
    $hash_out->{mean}   = $stat->mean();
    $hash_out->{sd}     = $stat->standard_deviation();
    $hash_out->{count}  = $stat->count();
    $hash_out->{per25}  = $stat->percentile(25);
    $hash_out->{per75}  = $stat->percentile(75);
    $hash_out->{min}    = $stat->min();
    $hash_out->{max}    = $stat->max();
    $hash_out->{median} = $stat->median();
    $hash_out->{sum}    = $stat->sum();

    return $hash_out;
}

sub write_log {

    my ( $log, $data, $VERSION ) = @_;

    # NB: We will use anonymous (no effect on $data)
    chomp( my $ncpuhost = qx{/usr/bin/nproc} ) // 1;

    my $info = {
        date     => ( strftime "%a %b %e %H:%M:%S %Y", localtime ),
        ncpuhost => ( 0 + $ncpuhost ),                                # coercing it to be a number
        hostname => hostname,
        id       => time . substr( "00000$$", -5 ),                   # string
        version  => $VERSION,
        user     => $ENV{LOGNAME} || $ENV{USER} || getpwuid($<)
    };

    # Saving file
    say BOLD GREEN "Writing <$log> file\n" if $verbose;
    write_json(
        {
            filepath => $log,
            data     => { info => $info, data => $data }
        }
    );
}

sub write_alignment {

    my ( $output, $array ) = @_;

    # Watch out for RAM usage!!!
    open( my $fh, ">", $output );
    print $fh join "\n", @$array;
    close $fh;
}

sub read_json {

    my $file = shift;

    # NB: hp.json is non-UTF8
    # malformed UTF-8 character in JSON string, at character offset 680 (before "\x{fffd}r"\n      },...")
    my $str =
      $file =~ /hp\.json/ ? path($file)->slurp : path($file)->slurp_utf8;
    return decode_json($str);    # Decode to Perl data structure
}

sub read_yaml {

    return LoadFile(shift);      # Decode to Perl data structure
}

sub write_json {

    my $arg       = shift;
    my $file      = $arg->{filepath};
    my $json_data = $arg->{data};

    # Note that canonical DOES not match the order of nsort from Sort:.Naturally
    my $json = JSON::XS->new->utf8->canonical->pretty->encode($json_data);
    path($file)->spew_utf8($json);
    return 1;
}

sub program_header {

    my $VERSION = shift;
    my $str     = <<EOF;
****************************************
*    Rank against cohort (BFF/PXF)     *
*          - PHENO-RANKER -            *
*          Version: $VERSION            *
*      (C) 2023 Manuel Rueda, PhD      *
*    GNU General Public License v3     *
****************************************
EOF
    return $str;
}

=head1 NAME

pheno-ranker: A script that compares a given BFF/PXF file against a BFF/PXF cohort

=head1 SYNOPSIS


pheno-ranker -r <individuals.json> -t <patient.json> [-options]

     Arguments:                       
       -r|reference-file              BFF/PXF file (JSON array)
       -t|target-file                 BFF/PXF file (JSON)

     Options:
       -o                             Output file [matrix.txt]
       -debug                         Print debugging (from 1 to 5, being 5 max)
       -e|export                      Export miscellaena JSON files
       -h|help                        Brief help message
       -hpo                           Include HPO ascendant terms (if present)
       -log                           Save log file (JSON). If no argument is given then the log is named [pheno-ranker-log.json]
       -man                           Full documentation
       -max-out                       Print only N of comparisons (used with --t)  [50]
       -nc|-no-color                  Don't print colors to STDOUT
       -sort-by                       Sort reference-patient comparison by Hamming-distance or Jaccard-index [>hamming|jaccard]
       -v|verbose                     Verbosity on
       -V|version                     Print version
       -w|weights                     YAML file with weights

=head1 DESCRIPTION

pheno-ranker: A script that compares a given BFF/PXF file against a BFF/PXF cohort

=head1 SUMMARY

pheno-ranker: A script that compares and ranks (by dissimilarity) a given BFF/PXF file against a BFF/PXF cohort

=head1 INSTALLATION

 $ cpanm sudo --installdeps .

=head3 System requirements

  * Ideally a Debian-based distribution (Ubuntu or Mint), but any other (e.g., CentOs, OpenSuse) should do as well.
  * Perl 5 (>= 5.10 core; installed by default in most Linux distributions). Check the version with "perl -v"
  * 1GB of RAM.
  * 1 core (it only uses one core per job).
  * At least 1GB HDD.

=head1 HOW TO RUN PHENO-RANKER

For executing pheno-ranker you will need:

=over

=item Input file(s):
      
A PXF or BFF file(s) in JSON format. The reference cohort must be a JSON array, where each individual data are consolidated in one object. 

If no C<--t> argument is provided then it will compute intra-cohort comparison only. If C<--t> argument is provided then the target JSON will be compared against the C<-r> reference cohort.

=back

B<Examples:>

 $ ./pheno-ranker -r phenopackets.json  # intra-cohort

 $ ./pheno-ranker -r phenopackets.json -o my_matrix.txt # intra-cohort

 $ ./pheno-ranker -r phenopackets.json -w weights.yaml  # intra-cohort with weights

 $ $path/pheno-ranker -t patient.json -r individuals.json -max-out 100 # patient-cohort

=head2 COMMON ERRORS AND SOLUTIONS

 * Error message: Foo
   Solution: Bar

 * Error message: Foo
   Solution: Bar

=head1 AUTHOR 

Written by Manuel Rueda, PhD. Info about CNAG can be found at L<https://www.cnag.crg.eu>.

=head1 COPYRIGHT AND LICENSE

This PERL file is copyrighted. See the LICENSE file included in this distribution.

=cut
